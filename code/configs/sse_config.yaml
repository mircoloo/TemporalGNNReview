# -----------------------------------------------------------------
# Configuration for the NASDAQ market (for the NEW DGDNN model)
# -----------------------------------------------------------------

# Parameters related to data loading and time periods
dataset_params:
  market: 'SSE'
  train_sedate: ['2016-05-01', '2017-06-30'] #ORIGINAL FROM PAPER
  #train_sedate: ['2010-05-01', '2017-06-30']  
  val_sedate: ['2017-07-01', '2017-12-31']
  #val_sedate: ['2017-07-01', '2018-07-01']
  test_sedate: ['2018-01-01', '2019-12-31']
  #test_sedate: ['2018-07-02', '2022-12-31']
  window_size: 14  # From paper: τ = 19
  use_fast_approximation: false

# -----------------------------------------------------------------

# Parameters defining the NEW DGDNN model architecture
model_params:
  DGDNN:
    layers: 5          # From paper: L = 8
    expansion_step: 3  # From paper: K = 9
    num_heads: 3   # From paper should be 3
    active_layers: [true, true, true, true, true]

    # --- New simplified attention parameters ---
    # The output size for ALL attention layers. From paper's "embedding dimension".
    embedding_output_size: 128
    # The size of the internal MLP inside the attention block. 256 is a sensible default.
    embedding_hidden_size: 256
    # The size the raw features are projected to. Must be divisible by num_heads (3). 96 is a good choice.
    raw_feature_size: 96

    # --- Calculated lists based on the new rules ---
    # Length must be layers + 1 = 9. First element must be 5 * window_size = 95.
    diffusion_size: [70, 128, 256, 512, 256, 128]

    # Length must be layers = 8. Values are calculated input dimensions for each attention layer.
    embedding_size:
      - 224  # Layer 0: diffusion_size[1] + raw_feature_size = 128 + 96
      - 384  # Layer 1: diffusion_size[2] + embedding_output_size = 256 + 128
      - 640  # Layer 2: diffusion_size[3] + embedding_output_size = 512 + 128
      - 384  # Layer 3: diffusion_size[4] + embedding_output_size = 256 + 128
      - 256  # Layer 4: diffusion_size[5] + embedding_output_size = 128 + 128
  GraphWaveNet:
    

# -----------------------------------------------------------------

# Parameters for the training process
training_params:
  learning_rate: 2e-4     # From paper: 2e-4
  weight_decay: 1.5e-5     # From paper: 1.5e-5
  epochs: 1200               # From paper
  neighbour_radius_coeff: 8.6e-3  # From paper: α = 2.9e-3